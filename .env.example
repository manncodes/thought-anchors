# vLLM server for Split LLaMA model inference
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_MODEL_NAME=

# vLLM server for judge model (GPT-OSS) - classification/labeling
VLLM_JUDGE_BASE_URL=http://localhost:8001/v1
VLLM_JUDGE_MODEL_NAME=

# Data directory for rollout results
DATA_DIR=./math_rollouts

# Backend server
HOST=0.0.0.0
PORT=8000

# Existing API keys (for upstream providers)
OPENROUTER_API_KEY=
NOVITA_API_KEY=
TOGETHER_API_KEY=
FIREWORKS_API_KEY=
